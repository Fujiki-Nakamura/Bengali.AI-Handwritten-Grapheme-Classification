{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as alb\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "\n",
    "input_d = Path('../inputs')\n",
    "df_train = pd.read_csv(input_d/'train.csv')\n",
    "h, w =  137, 236\n",
    "\n",
    "X_train = np.load(input_d/'X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-03-13\n",
    "\n",
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 128, 224\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    # alb.Cutout(num_holes=8, max_h_size=int(input_h * 0.15), max_w_size=int(input_w * 0.15), fill_value=0, p=p),\n",
    "    alb.CoarseDropout(max_holes=3, max_height=32, max_width=, min_holes=1, min_height=8, min_width=32, fill_value=127, p=p),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 15\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-03-13\n",
    "\n",
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 128, 224\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    # alb.Cutout(num_holes=8, max_h_size=int(input_h * 0.15), max_w_size=int(input_w * 0.15), fill_value=0, p=p),\n",
    "    alb.CoarseDropout(max_holes=4, max_height=32, max_width=128, min_holes=1, min_height=8, min_width=16, fill_value=127, p=p),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 15\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 128, 224\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    alb.Cutout(num_holes=8, max_h_size=int(input_h * 0.15), max_w_size=int(input_w * 0.15), fill_value=127, p=p),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 15\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-02-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from augment import GridMask\n",
    "\n",
    "\n",
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 224, 224\n",
    "# input_h, input_w = 137, 236\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    alb.ShiftScaleRotate(shift_limit=0.075, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=p),\n",
    "    GridMask(num_grid=3, p=p),\n",
    "\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 15\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(input_d/'X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 224, 224\n",
    "# input_h, input_w = 137, 236\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    # NOTE: NG alb.RandomContrast(limit=0.2, always_apply=False, p=p),\n",
    "    # alb.MedianBlur(blur_limit=21, always_apply=False, p=p),\n",
    "    # alb.Blur(blur_limit=21, always_apply=False, p=p),\n",
    "    alb.GaussianBlur(blur_limit=31, always_apply=False, p=p),\n",
    "    alb.Cutout(num_holes=1, max_h_size=int(224*0.35), max_w_size=int(224*0.35), fill_value=0, always_apply=False, p=p),\n",
    "    alb.Cutout(num_holes=1, max_h_size=int(224*0.35), max_w_size=int(224*0.35), fill_value=0, always_apply=False, p=p),\n",
    "    alb.ShiftScaleRotate(shift_limit=0.075, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=p),\n",
    "    # alb.GaussNoise(var_limit=(10.0, 50.0), mean=127.5, always_apply=False, p=0.5),\n",
    "    # NOTE: NG alb.RandomBrightness(limit=0.2, always_apply=False, p=p),\n",
    "    # alb.GridDistortion(num_steps=7, distort_limit=0.3, interpolation=1, border_mode=0, value=0, mask_value=None, always_apply=False, p=p),\n",
    "    # alb.ElasticTransform(alpha=1, sigma=30, alpha_affine=20, interpolation=1, border_mode=0, value=0, mask_value=None, always_apply=False, approximate=False, p=p),\n",
    "    # NOTE: ValueError: This transformation expects 3-channel images alb.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=p),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 15\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 224, 224\n",
    "# input_h, input_w = 137, 236\n",
    "p = 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    alb.ElasticTransform(alpha=1, sigma=50, alpha_affine=20, interpolation=1, border_mode=0, value=0, mask_value=None, always_apply=False, approximate=False, p=p),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 7\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 2\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(input_d/'X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i =  0\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "input_h, input_w = 224, 224\n",
    "# input_h, input_w = 137, 236\n",
    "p = 0.5  # 1.0\n",
    "transform_list = [\n",
    "    alb.Resize(input_h, input_w),\n",
    "    alb.Cutout(num_holes=1, max_h_size=int(input_h*0.35), max_w_size=int(input_w*0.35), fill_value=255, always_apply=False, p=p),\n",
    "    alb.Cutout(num_holes=1, max_h_size=int(input_h*0.35), max_w_size=int(input_w*0.35), fill_value=255, always_apply=False, p=p),\n",
    "    alb.ShiftScaleRotate(shift_limit=0.075, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=p),\n",
    "    # ToTensor(),\n",
    "]\n",
    "transform = alb.Compose(transform_list)\n",
    "\n",
    "n_transformed = 7\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 2\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(input_d/'X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.Cutout(num_holes=1, max_h_size=int(h*0.35), max_w_size=int(w*0.35), fill_value=255, always_apply=False, p=1.)\n",
    "\n",
    "n_transformed = 7\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 2\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.Cutout(num_holes=1, max_h_size=int(h*0.4), max_w_size=int(w*0.4), fill_value=255, always_apply=False, p=1.)\n",
    "\n",
    "n_transformed = 7\n",
    "transformed_list = []\n",
    "for i in range(n_transformed):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "nrow = 2\n",
    "ncol = 4\n",
    "plt.figure(figsize=(ncol*8, nrow*6))\n",
    "plt.subplot(nrow, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(n_transformed):\n",
    "    plt.subplot(nrow, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class RandomErasing(alb.ImageOnlyTransform):  # pylint: disable=abstract-method\n",
    "    def __init__(\n",
    "        self, scale=(0.02, 0.4), rate=(1 / 3, 3), alpha=None, always_apply=False, p=0.5\n",
    "    ):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "        self.scale = scale\n",
    "        self.rate = rate\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def apply(self, img, **data):\n",
    "        del data\n",
    "        for _ in range(30):\n",
    "            s = img.shape[0] * img.shape[1] * random.uniform(*self.scale)\n",
    "            r = np.exp(random.uniform(np.log(self.rate[0]), np.log(self.rate[1])))\n",
    "            ew = int(np.sqrt(s / r))\n",
    "            eh = int(np.sqrt(s * r))\n",
    "            if ew <= 0 or eh <= 0 or ew >= img.shape[1] or eh >= img.shape[0]:\n",
    "                continue\n",
    "            ex = random.randint(0, img.shape[1] - ew - 1)\n",
    "            ey = random.randint(0, img.shape[0] - eh - 1)\n",
    "\n",
    "            img = np.copy(img)\n",
    "            rc = np.array([random.randint(0, 255) for _ in range(img.shape[-1])])\n",
    "            if self.alpha:\n",
    "                img[ey : ey + eh, ex : ex + ew, :] = (\n",
    "                    img[ey : ey + eh, ex : ex + ew, :] * (1 - self.alpha)\n",
    "                    + rc * self.alpha\n",
    "                ).astype(img.dtype)\n",
    "            else:\n",
    "                img[ey : ey + eh, ex : ex + ew, :] = rc[np.newaxis, np.newaxis, :]\n",
    "            break\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0][:, :, np.newaxis]\n",
    "\n",
    "transform = RandomErasing(p=1.)\n",
    "\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0[:, :, 0], 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i][:, :, 0], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(input_d/'X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.ShiftScaleRotate(\n",
    "    shift_limit=0.075, scale_limit=0, rotate_limit=0, interpolation=1, border_mode=0, value=0., mask_value=None, \n",
    "    always_apply=False, p=1.0\n",
    ")\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.ShiftScaleRotate(\n",
    "    shift_limit=0.075, scale_limit=0, rotate_limit=0, interpolation=1, border_mode=0, value=None, mask_value=None, \n",
    "    always_apply=False, p=1.0\n",
    ")\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.ShiftScaleRotate(\n",
    "    shift_limit=0., scale_limit=0.1, rotate_limit=0, interpolation=1, border_mode=0, value=None, mask_value=None, \n",
    "    always_apply=False, p=1.0\n",
    ")\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train[0]\n",
    "\n",
    "transform = alb.ShiftScaleRotate(\n",
    "    shift_limit=0., scale_limit=0., rotate_limit=45, interpolation=1, border_mode=0, value=None, mask_value=None, \n",
    "    always_apply=False, p=1.0\n",
    ")\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i = 100\n",
    "X_train_0 = X_train[sample_i]\n",
    "\n",
    "transform = alb.ShiftScaleRotate(\n",
    "    shift_limit=0.075, scale_limit=0.1, rotate_limit=45, interpolation=1, border_mode=0, value=None, mask_value=None, \n",
    "    always_apply=False, p=1.0\n",
    ")\n",
    "transformed_list = []\n",
    "for i in range(3):\n",
    "    transformed = transform(image=X_train_0)['image']\n",
    "    transformed_list.append(transformed)\n",
    "\n",
    "ncol = 4\n",
    "plt.figure(figsize=(4*8, 6))\n",
    "plt.subplot(1, ncol, 1)\n",
    "plt.imshow(X_train_0, 'gray')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, ncol, i+2)\n",
    "    plt.imshow(transformed_list[i], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(input_d/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import yaml\n",
    "\n",
    "config = '../src/cfgs/default.yaml'\n",
    "with open(config, 'r') as f:\n",
    "    y = yaml.load(f, Loader=yaml.Loader)\n",
    "cfg = addict.Dict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in cfg.data.augmentation:\n",
    "    name = d.split('/')[0]\n",
    "    v = d.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for p in v.split(', '):\n",
    "    d[p.split('=')[0]] = eval(p.split('=')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# CUDA_VISIBLE_DEVICES=0 python validate.py default.yaml\n",
    "2020-01-12 02:28:05,729 - Logging at ../logs/20200109120411\n",
    "2020-01-12 02:28:05,729 - {'general': {'random_state': 42, 'device': 'cuda:0', 'config': 'default.yaml', 'logdir': '../logs/20200109120411'}, 'data': {'X_train': '../inputs/X_train.npy', 'y_train': '../inputs/y_train.npy'}, 'model': {'input_dim': 3, 'n_outputs': 186, 'name': 'resnet18', 'pretrained': True}, 'training': {'loss': 'CrossEntropyLoss', 'n_splits': 5, 'batch_size': 256, 'epochs': 30, 'n_worker': 4, 'single_fold': False, 'single_iter': False}, 'optimizer': {'name': 'Adam', 'lr': 0.001, 'weight_decay': 0.0}, 'valid': {'expid': '20200109120411', 'best_model_name': 'bestScore.pt'}}\n",
    "2020-01-12 02:28:18,783 - Loaded X_train, y_train\n",
    "2020-01-12 02:29:53,612 - [20200109120411] bestScore.pt acc/grapheme 0.0016 vowel 0.0622 consonant 0.1168 final_score 0.0635\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../src')\n",
    "expid = '20200109120411'\n",
    "config = f'../logs/{expid}/config.yaml'\n",
    "best_model_name = 'bestScore.pt'\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import addict\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from common import component_list, LOGDIR, N_GRAPHEME, N_VOWEL, N_CONSONANT\n",
    "from dataset import MyDataset as Dataset\n",
    "import models\n",
    "import utils\n",
    "\n",
    "\n",
    "# config\n",
    "with open(config, 'r') as f:\n",
    "    y = yaml.load(f, Loader=yaml.Loader)\n",
    "cfg = addict.Dict(y)\n",
    "cfg.general.config = config\n",
    "cfg.general.device = 'cpu'\n",
    "\n",
    "# misc\n",
    "device = cfg.general.device\n",
    "random.seed(cfg.general.random_state)\n",
    "os.environ['PYTHONHASHSEED'] = str(cfg.general.random_state)\n",
    "np.random.seed(cfg.general.random_state)\n",
    "torch.manual_seed(cfg.general.random_state)\n",
    "\n",
    "# log\n",
    "cfg.general.logdir = str(LOGDIR/expid)\n",
    "# if not os.path.exists(cfg.general.logdir):\n",
    "#     os.makedirs(cfg.general.logdir)\n",
    "# os.chmod(cfg.general.logdir, 0o777)\n",
    "# logger = utils.get_logger(os.path.join(cfg.general.logdir, 'valid.log'))\n",
    "# logger.info(f'Logging at {cfg.general.logdir}')\n",
    "# logger.info(cfg)\n",
    "cfg.general.logdir = Path(cfg.general.logdir)\n",
    "# shutil.copyfile(str(args.config), cfg.general.logdir/'config_val.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_train = np.load(cfg.data.X_train, allow_pickle=True)\n",
    "y_train = np.load(cfg.data.y_train, allow_pickle=True)\n",
    "# logger.info('Loaded X_train, y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV\n",
    "kf = KFold(n_splits=cfg.training.n_splits, shuffle=True, random_state=cfg.general.random_state)  # noqa\n",
    "probas = {\n",
    "    'grapheme': np.zeros((len(X_train), N_GRAPHEME)),\n",
    "    'vowel': np.zeros((len(X_train), N_VOWEL)),\n",
    "    'consonant': np.zeros((len(X_train), N_CONSONANT)),\n",
    "}\n",
    "for fold_i, (train_idx, valid_idx) in enumerate(kf.split(y_train)):\n",
    "    X_valid_ = X_train[valid_idx]\n",
    "    y_valid_ = y_train[valid_idx]\n",
    "    valid_set = Dataset(X_valid_, y_valid_, cfg, mode='valid')\n",
    "    valid_loader = DataLoader(\n",
    "        valid_set, batch_size=cfg.training.batch_size, shuffle=False,\n",
    "        num_workers=cfg.training.n_worker)\n",
    "\n",
    "    # pretrained model\n",
    "    fold_d = cfg.general.logdir/f'fold_{fold_i}'\n",
    "    checkpoint = fold_d/best_model_name\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    model = models.get_model(cfg=cfg)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    proba = {'grapheme': [], 'vowel': [], 'consonant': []}\n",
    "    pbar = tqdm(total=len(valid_loader), desc=f'Fold {fold_i+1}')\n",
    "    with torch.no_grad():\n",
    "        for input_, target in valid_loader:\n",
    "            input_ = input_.to(cfg.general.device)\n",
    "            output = model(input_)\n",
    "            outputs = torch.split(output, [N_GRAPHEME, N_VOWEL, N_CONSONANT], dim=1)\n",
    "            proba['grapheme'].append(F.softmax(outputs[0], dim=1).detach().cpu().numpy())\n",
    "            proba['vowel'].append(F.softmax(outputs[1], dim=1).detach().cpu().numpy())\n",
    "            proba['consonant'].append(F.softmax(outputs[2], dim=1).detach().cpu().numpy())\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    for component in component_list:\n",
    "        probas[component][valid_idx, :] = np.concatenate(proba[component], axis=0)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas['grapheme'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas['grapheme'].sum(1).sum(), len(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas['grapheme'].argmax(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas['grapheme'][valid_idx, :].argmax(1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[valid_idx, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "for component in component_list:\n",
    "    pred[component] = probas[component].argmax(axis=1)\n",
    "\n",
    "acc = {}\n",
    "for component_i, component in enumerate(component_list):\n",
    "    acc[component] = metrics.accuracy_score(y_train[:, component_i], pred[component])\n",
    "\n",
    "scores = []\n",
    "for component_i, component in enumerate(component_list):\n",
    "    scores.append(metrics.recall_score(y_train[:, component_i], pred[component], average='macro'))\n",
    "final_score = np.average(scores, weights=[2, 1, 1])\n",
    "\n",
    "log = f'[{expid}] {cfg.valid.best_model_name} '\n",
    "log += f'acc/grapheme {acc[\"grapheme\"]:.4f} vowel {acc[\"vowel\"]:.4f} consonant {acc[\"consonant\"]:.4f} '  # noqa\n",
    "log += f'final_score {final_score:.4f}'\n",
    "# logger.info(log)\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 128\n",
    "\n",
    "TRAIN = ['/kaggle/input/bengaliai-cv19/train_image_data_0.parquet',\n",
    "         '/kaggle/input/bengaliai-cv19/train_image_data_1.parquet',\n",
    "         '/kaggle/input/bengaliai-cv19/train_image_data_2.parquet',\n",
    "         '/kaggle/input/bengaliai-cv19/train_image_data_3.parquet']\n",
    "TRAIN = [train_data.replace('/kaggle/input/bengaliai-cv19', '../inputs') for train_data in TRAIN]\n",
    "\n",
    "\n",
    "OUT_TRAIN = 'train.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_interval = 10000\n",
    "plot_i = 0\n",
    "X_train_list = []\n",
    "for dataset_i in range(4):\n",
    "    df = pd.read_parquet(TRAIN[dataset_i])\n",
    "    n_samples = len(df)\n",
    "    for sample_i in tqdm(list(range(n_samples))):\n",
    "        img = 255 - df.iloc[sample_i, 1:].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "        img = crop_resize(img)\n",
    "        X_train_list.append(img)\n",
    "        if plot_i % plot_interval == 0:\n",
    "            plt.imshow(img, 'gray')\n",
    "            plt.show()\n",
    "        plot_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(X_train_list, axis=0)\n",
    "np.save(input_d/'X_train_128x128.npy', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(input_d/'y_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-01-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(input_d/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['grapheme_root'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapheme_dummy = pd.get_dummies(df_train['grapheme_root']).values\n",
    "vowel_dummy = pd.get_dummies(df_train['vowel_diacritic']).values\n",
    "consonant_dummy = pd.get_dummies(df_train['consonant_diacritic']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapheme_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonant_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([grapheme_dummy, vowel_dummy, consonant_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(input_d/'y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.loc[:, ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "np.save(input_d/'y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
