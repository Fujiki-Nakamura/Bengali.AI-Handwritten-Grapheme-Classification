general:
    random_state: 42
    device: "cuda:0"
    logdir: "../logs"
    expid: ""

data:
    X_train: "../inputs/X_train.npy"
    y_train: "../inputs/y_train.npy"
    # input_h: 137
    # input_w: 236
    input_h: 224
    input_w: 224
    augmentation: [
        # "ShiftScaleRotate/shift_limit=0.075, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=0.5",
        # "Cutout/num_holes=1, max_h_size=int(137*0.35), max_w_size=int(236*0.35), fill_value=0, always_apply=False, p=0.5"
    ]

cutmix:
    prob: !!python/float 0.5
    beta: !!python/float 1.0
mixup:
    prob: !!python/float 0
    beta: !!python/float 0
    # prob: !!python/float 1.0
    # beta: !!python/float  1.0

model:
    input_dim: 1
    n_outputs: 186
    name: "resnet34"
    pretrained: !!python/bool False

training:
    loss: "CrossEntropyLoss"
    # NOTE: ['grapheme', 'vowel', 'consonant']
    coef_list: [2.0, 1.0, 1.0]
    # coef_list: [1.0, 1.0, 1.0]
    split: "KFold"
    n_splits: 5
    target_folds: [1,]
    # target_folds: [1, 2, 3, 4, 5]
    batch_size: 256
    epochs: 3000
    n_worker: 8
    single_fold: !!python/bool False
    single_iter: !!python/bool False
    # lr_scheduler:
    #     name: "CosineAnnealingLR"
    #     args: "T_max=10, eta_min=1e-3, last_epoch=-1"
    #     name: "ReduceLROnPlateau"
    #     args: "mode='min', factor=0.1, patience=10"

optimizer:
    # name: "SGD"
    # args: "lr=1e-1, weight_decay=0., momentum=0.9, nesterov=True"
    name: "RAdam"
    args: "lr=1e-3, weight_decay=0."
    # args: "lr=1e-3, weight_decay=1e-4"
