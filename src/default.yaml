general:
    random_state: 42
    device: "cuda:0"
    multi_gpu: !!python/bool True
    logdir: "../logs"
    expid: ""

data:
    X_train: "../inputs/X_train.npy"
    y_train: "../inputs/y_train.npy"
    input_h: 224
    input_w: 224
    train_transform: "[
        alb.Resize(height=224, width=224),
        alb.OneOf([
            alb.ShiftScaleRotate(shift_limit=0.03125, scale_limit=0.20, rotate_limit=20, border_mode=0, value=0, p=1.0),
            alb.IAAAffine(scale=(0.8, 1.2), translate_percent=(-0.03125, 0.03125), rotate=(-10, 10), shear=(-40, 40), mode='constant', p=1.0),
        ]),
        alb.CoarseDropout(max_holes=4, max_height=32, max_width=128, min_holes=1, min_height=8, min_width=16, fill_value=0, p=0.5)
    ]"
    valid_transform: "[
        alb.Resize(height=224, width=224),
    ]"
    # alb.Cutout(num_holes=8, max_h_size=int(128*0.15), max_w_size=int(224*0.15), fill_value=0, p=0.5),
    # augment.GridMask(num_grid=3, rotate=15, p=0.5),

cutmix:
    prob: !!python/float 0.8
    beta: !!python/float 1.0
mixup:
    prob: !!python/float 0.
    beta: !!python/float 1.0

model:
    input_dim: 3
    input_c: 3
    n_outputs: 186
    pretrained: !!python/bool True
    name: "efficientnet-b4"
    resume: "../logs/20200315085210/fold_0/checkpoint.pt"

training:
    loss: "CrossEntropyLoss"
    ohem_loss: !!python/bool False
    ohem_rate: !!python/float 0.7
    ohem_epoch: 30
    coef_list: [1.0, 1.0, 1.0]
    split: "KFold"
    n_splits: 20
    target_folds: [1,]
    # with_x_percent_fold_1_of_5: !!python/float 0.95
    batch_size: 512  # 256  # 128
    epochs: 500
    n_worker: 8
    single_fold: !!python/bool False
    single_iter: !!python/bool False
    lr_scheduler:
        # name: "MultiStepLR"
        # args: "milestones=[1,], gamma=0.1"
        # name: "CosineAnnealingWarmRestarts"
        # args: "T_0=20, T_mult=1, eta_min=0."

optimizer:
    # name: "SGD"
    # args: "lr=0.02, weight_decay=0., momentum=0.9, nesterov=True"
    name: "RAdam"
    args: "lr=1e-3, weight_decay=1e-4"
