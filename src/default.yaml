general:
    random_state: 42
    device: "cuda:0"
    logdir: "../logs"
    expid: ""

data:
    X_train: "../inputs/X_train.npy"
    y_train: "../inputs/y_train.npy"
    input_h: 224  # 137
    input_w: 224  # 236
    augmentation: [
        "GaussianBlur/blur_limit=31, always_apply=False, p=0.5",
        "Cutout/num_holes=1, max_h_size=int(224*0.35), max_w_size=int(224*0.35), fill_value=0, always_apply=False, p=0.5",
        "Cutout/num_holes=1, max_h_size=int(224*0.35), max_w_size=int(224*0.35), fill_value=0, always_apply=False, p=0.5",
        "ShiftScaleRotate/shift_limit=0.075, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=0.5",
    ]

cutmix:
    prob: !!python/float 0.  # 0.5
    beta: !!python/float 0.  # 1.0
mixup:
    prob: !!python/float 0.  # 0.5
    beta: !!python/float 0.  # 1.0

model:
    input_dim: 1
    n_outputs: 186
    name: "resnet34"
    pretrained: !!python/bool False
    # resume: "../logs/20200127144339/fold_0/checkpoint.pt"

training:
    loss: "CrossEntropyLoss"
    split: "KFold"
    n_splits: 5
    target_folds: [1, ]  # 2, 3, 4, 5]
    batch_size: 256
    epochs: 1000
    n_worker: 8
    single_fold: !!python/bool False
    single_iter: !!python/bool False
    # lr_scheduler:
    #     name: "CosineAnnealingLR"
    #     args: "T_max=10, eta_min=1e-3, last_epoch=-1"

optimizer:
    # name: "SGD"
    # args: "lr=1e-1, weight_decay=0., momentum=0.9, nesterov=True"
    name: "RAdam"
    args: "lr=1e-3, weight_decay=0."
